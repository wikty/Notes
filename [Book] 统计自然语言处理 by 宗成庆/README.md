[TOC]



# 第一章 绪论

## 基本概念

### 语音和语言

语音和文字是构成
语言的两个基本属性，语音是语言的物质外壳，文字则是记录语言的书
写符号系统［黄伯荣等，1991］。

语音学（phonetics）是研究人类发音特点，特别是语音发音特点，
并提出各种语音描述、分类和转写方法的科学。

### 自然语言处理和计算语言学

自然语言处理（natural language processing, NLP）也称自然语言理解
（natural language understanding, NLU），从人工智能研究的一开始，它
就作为这一学科的重要研究内容探索人类理解自然语言这一智能行为的
基本方法。

**计算语言学**实际上包括以语音为主要研究对象的语音学基础及其语音处理技术研
究和以词汇、句子、话语或语篇（discourse）及其词法、句法、语义和
语用等相关信息为主要研究对象的处理技术研究。

**自然语言处理**一般不再被看作是计算语言学范畴内的一个研究分支，而两者
基本上是处于同一层次上的概念。

从术语的字面上来看，似乎“计算语言学”更侧重于计算方法和语言
学理论等方面的研究，而“自然语言理解”更偏向于对语言认知和理解过
程等方面问题的研究，相对而言，“自然语言处理”包含的语言工程和应
用系统实现方面的含义似乎更多一些，但是，在很多情况下我们很难绝
对地区分开“计算语言学”、“自然语言理解”与“自然语言处理”三个术语
之间到底存在怎样的包含或重叠关系以及各自不同的内涵和外延。

### 图灵测试

实际上，人们在自然语言处理领域研究的任何一个应用系统都可以
拿来做图灵测试。按照人的标准对这些系统的输出结果进行评价，从而
判断计算机系统是否达到了“理解”的效果。显然，被测试系统所表现出
来的性能反映了计算机系统的“理解”能力。因此，我们从事自然语言理
解研究的任务也就是研究和探索针对具体应用目的的新方法和新技术，
使实现系统的性能表现尽量符合人类理解的标准和要求。

## 研究内容

### 语言的研究层级

如果撇开语音学研究的层面，自然语言处理研究的问题一般会涉及
自然语言的形态学、语法学、语义学和语用学等几个层次。

**形态学（morphology）**：形态学（又称“词汇形态学”或“词法”）是
语言学的一个分支，研究词的内部结构，包括屈折变化和构词法两个部
分。

**语法学（syntax）**：研究句子结构成分之间的相互关系和组成句子
序列的规则。其关注的中心是：为什么一句话可以这么说，也可以那么
说？

**语义学（semantics）**：是一门研究意义，特别是语言意义的学科
［毛茂臣，1988］。语义学的研究对象是语言的各级单位（词素、词、
词组、句子、句子群、整段整篇的话语和文章，乃至整个著作）的意
义，以及语义与语音、语法、修辞、文字、语境、哲学思想、社会环
境、个人修养的关系，等等［陆善采，1993］。它所关注的重点
是：这个语言单位到底说了什么？

**语用学（pragmatics）**：是现代语言学用来指从使用者的角度研究
语言，特别是使用者所作的选择、他们在社会互动中所受的制约、他们
的语言使用对信递活动中其他参与者的影响。，语
用学可以是集中在句子层次上的语用研究，也可以是超出句子，对语言
的实际使用情况的调查研究，甚至与会话分析、语篇分析相结合，研究
在不同上下文中的语句应用，以及上下文对语句理解所产生的影响。其
关注的重点在于：为什么在特定的上下文中要说这句话？

### 研究难点

所有自然语言应用都需要解决的关键问题就是**歧义消解**（disambiguation）问题
和**未知语言现象**的处理问题。

一方面，自然语言中大量存在的歧义现
象，无论在词法层次、句法层次，还是在语义层次和语用层次，无论哪
类语言单位，其歧义性始终都是困扰人们实现应用目标的一个根本问
题。因此，如何面向不同的应用目标，针对不同语言单位的特点，研究
歧义消解和未知语言现象的处理策略及实现方法，就成了自然语言处理
面临的核心问题。

另一方面，对于一个特定系统来说，总是有可能遇到未知词汇、未
知结构等各种意想不到的情况，而且每一种语言又都随着社会的发展而
动态变化着，新的词汇（尤其是一些新的人名、地名、组织机构名和专
用词汇）、新的词义、新的词汇用法（新词类），甚至新的句子结构都
在不断出现，尤其在口语对话或计算机网络对话（通过MSN、QQ、
GTalk、Skype等形式）、微博、博客等中，稀奇古怪的词语和话语结构
更是司空见惯。因此，一个实用的自然语言处理系统必须具有较好的未
知语言现象的处理能力，而且有足够的对各种可能输入形式的容错能
力，即我们通常所说的系统的鲁棒性（robustness）问题。

## 研究方法

### 理性主义和经验主义

一般认为，自然语言处理中存在着两种不同的研究方法，一种是理
性主义（rationalist）方法，另一种是经验主义（empiricist）方法。

**理性主义**方法认为，人的很大一部分语言知识是与生俱来的，由遗
传决定的。持这种观点的代表人物是美国语言学家乔姆斯基（Noam
Chomsky），他的内在语言官能（innate language faculty）理论被广泛地
接受。乔姆斯基认为，很难知道小孩在接收到极为有限的信息量的情况
下，在那么小的年龄如何学会了如此之多复杂的语言理解的能力。因
此，理性主义的方法试图通过假定人的语言能力是与生俱来的、固有的
一种本能来回避这些困难的问题。

在具体的自然语言问题研究中，理性主义方法主张建立符号处理系
统，由人工整理和编写初始的语言知识表示体系（通常为规则），构造
相应的推理程序，系统根据规则和程序，将自然语言理解为符号结构
——该结构的意义可以从结构中的符号的意义推导出来。按照这种思
路，在自然语言处理系统中，一般首先由词法分析器按照人编写的词法
规则对输入句子的单词进行词法分析，然后，语法分析器根据人设计的
语法规则对输入句子进行语法结构分析，最后再根据一套变换规则将语
法结构映射到语义符号（如逻辑表达式、语义网络、中间语言等）。

而**经验主义**的研究方法也是从假定人脑所具有的一些认知能力开始
的。因此，从这种意义上讲，两种方法并不是绝对对立的。但是，经验
主义的方法认为人脑并不是从一开始就具有一些具体的处理原则和对具
体语言成分的处理方法，而是假定孩子的大脑一开始具有处理联想
（association）、模式识别（pattern recognition）和通用化
（generalization）处理的能力，这些能力能够使孩子充分利用感官输入
来掌握具体的自然语言结构。在系统实现方法上，经验主义方法主张通
过建立特定的数学模型来学习复杂的、广泛的语言结构，然后利用统计
学、模式识别和机器学习等方法来训练模型的参数，以扩大语言使用的
规模。因此，经验主义的自然语言处理方法是建立在统计方法基础之上
的，因此，我们又称其为统计自然语言处理（statistical natural language
processing）方法。

在统计自然语言处理方法中，一般需要收集一些文本作为统计模型
建立的基础，这些文本称为语料（corpus）。经过筛选、加工和标注等
处理的大批量语料构成的数据库叫做语料库（corpus base）。由于统计
方法通常以大规模语料库为基础，因此，又称为基于语料（corpusbased）
的自然语言处理方法。

实际上，理性主义和经验主义试图刻画的是两种不同的东西。
Chomsky的生成语言学理论试图刻画的是人类思维（I-language）的模式
或方法。对于这种方法而言，某种语言的真实文本数据（E-language）
只是提供间接的证据，这种证据可以由以这种语言为母语的人来提供。
而经验主义方法则直接关心如何刻画这些真实的语言本身（Elanguage）
。Chomsky把语言的能力（linguistic competence）和语言的表
现（linguistic performance）区分开来了。他认为，语言的能力反映的是
语言结构知识，这种知识是说话人头脑中固有的，而语言表现则受到外
界环境诸多因素的影响，如记忆的限制、对环境噪声的抗干扰能力等。

### 发展历程

理性主义和经验主义在基本出发点上的差异导致了在很多领域中都
存在着两种不同的研究方法和系统实现策略，这些领域在不同的时期被
不同的方法主宰着。

* 在20世纪20年代到60年代的近40年时间里，经验主义方法在语言
  学、心理学、人工智能等领域中处于主宰的地位，人们在研究语言运用
  的规律、言语习得、认知过程等问题时，都是从客观记录的语言、语音
  数据出发，进行统计、分析和归纳，并以此为依据建立相应的分析或处
  理系统。

* 大约从20世纪60年代中期到20世纪80年代中后期，语言学、心理
  学、人工智能和自然语言处理等领域的研究几乎完全被理性主义研究方
  法控制着，这一时期的计算语言学理论得到了长足
  的发展并逐渐成熟，出现了一系列重要的理论研究成果，其中，乔姆斯
  基的形式语言理论［Chomsky,1956］是影响最大的早期计算语言学句法
  理论。后来乔姆斯基又分别在20世纪50年代和70年代提出了转换生成语
  法和约束管辖理论。随后，很多学者又提出了扩充转移网络、词汇功能
  语法、功能合一语法、广义短语结构语法和中心驱动的短语结构语法等。

  1969年厄尔利（J.Earley）提出了Earley句法分析算法
  ［Earley,1970］；1980年马丁·凯（Martin Kay）提出了线图句法分析算
  法（chart parsing）［Allen,1995］；1985年富田胜（M.Tomita）提出了
  Tomita句法分析算法［Tomita,1985］。这些研究成果为自然语言自动句
  法分析奠定了良好的理论基础。在语义分析方面，1966年菲尔摩
  （C.J.Filmore）提出了格语法；1968年美国心理学家奎廉
  （M.R.Quilian）在研究人类联想记忆时提出了语义网络（semantic
  network）的概念；1972年美国人工智能专家西蒙斯（Simmous）等人首
  先将语义网络用于自然语言理解系统中；1974年威尔克斯（Y.Wilks）提
  出了优选语义学；20世纪70年代初，美国数理逻辑学家蒙塔格（Richard
  Montague）提出的蒙塔格语法，首次提出了利用数理逻辑来研究自然语
  言的句法结构和语义关系的设想，为自然语言处理研究开辟了一条新的
  途径。

* 大约在20世纪80年代后期，人们越来越多地关注工程化、实用化的
  解决问题方法，经验主义方法被人们重新认识并得到迅速发展。在自然
  语言处理研究中，重要的标志是基于语料库的统计方法被引入到自然语
  言处理中，并发挥出重要作用，很多人开始研究和关注基于大规模语料
  的统计机器学习方法及其在自然语言处理中的应用，并客观地比较和评
  价各种方法的性能。

  在这一时期，基于
  语料库的机器翻译（corpus-based machine translation）方法得到了充分发
  展，尤其是IBM的研究人员提出的基于噪声信道模型（noisy channel
  model）的统计机器翻译（statistical machine translation）模型［Brown et
  al.,1990,1993］及其实现的Candide翻译系统［Berger et al.,1994］，为经
  验主义方法的复苏和兴起吹响了号角，并成为机器翻译领域的里程碑。

  隐马尔可夫模型（hidden Markov model,
  HMM）等统计方法在语音识别中的成功运用对自然语言处理的发展也
  起到了推波助澜甚至是关键的作用，统计机器翻译中的许多思想都来源
  于语音识别中统计模型成功运用的经验，或在某种程度上受到了统计语
  音识别研究思路的启发。实践证明，除了语音识别和机器翻译以外，很
  多自然语言处理的研究任务，包括汉语自动分词和词性标注、文字识
  别、拼音法汉字输入等，都可以用噪声信道模型来描述和实现。

* 在20世纪80年代末期和90年代初期，曾经引发了关于理性主义和经
  验主义两种不同观点的激烈争论。但随着时间的推移，当人们从那些空
  泛的辩论中冷静下来以后，逐渐认识到，无论是理性主义也好，还是经
  验主义也罢，任何一种方法都不可能完全解决自然语言处理这一复杂问
  题，只有将两种方法很好地结合起来，寻找一种融合的解决问题办法，
  甚至建立一种新的理论方法才是自然语言处理研究的真正出路。

回顾自然语言处理技术半个多世纪的发展历程，黄昌宁等
（2002b）认为这一领域的研究取得了两点重要认识，即：①对于句法
分析，基于单一标记的短语结构规则是不充分的；②短语结构规则在真
实文本中的分布呈现严重的扭曲。换言之，有限数目的短语结构规则不
能覆盖大规模真实语料中的语法现象，这与原先的预期大相径庭。NLP
技术的发展在很大程度上受到这两个事实的影响。从这个意义上说，本
领域中称得上里程碑式的成果有三个：①复杂特征集和合一语法的提
出；②语言学研究中词汇主义的建立；③语料库方法和统计语言模型的
广泛运用。

### 研究现状

如果我们不考虑具体的
技术分支，从自然语言处理研究的总体状况来看，可以简单地用以下三
点来粗略地反映自然语言处理技术研究的现状：

* 已开发完成一批颇具影响的语言资源库，部分技术已达到或
  基本达到实用化程度，并在实际应用中发挥着巨大作用。例如，北京大
  学语料库和综合型语言知识库［俞士汶等，2003a,2003b］、
  HowNet〔10〕、LDC（Linguistic Data Consortium）〔11〕语言资源等
* 许多新的研究方向不断出现。正如我们前面指出的，受实际
  应用的驱动，自然语言处理技术不断与新的相关技术相结合，用于研究
  和开发越来越多的实用技术。
* 许多理论问题尚未得到根本性的解决。尽管许多理论模型在
  自然语言处理研究中发挥着重要作用，并且很多方法已经得到实际应用，如上下文无关文法、HMM、噪声信道模型等，但是，许多重要的
  问题仍未得到彻底、有效的解决，如语义理解问题、句法分析问题、指
  代歧义消解问题、汉语自动分词中的未登录词（unknown word）识别问
  题等。纵观整个自然语言处理领域，尚未建立起一套完整、系统的理论
  框架体系。许多理论研究仍处于盲目的探索阶段，如尝试一些新的机器
  学习方法或未曾使用过的数学模型，这些尝试和实验带有很强的主观性
  和盲目性。在技术实现上，许多改进往往仅限于对一些边角问题的修修
  补补，或者只是针对特定条件下一些具体问题的处理，未能从根本上建
  立一套广泛适用的、鲁棒的处理策略。总之，面对自然语言问题的复杂
  性和多变性，现有的理论模型和方法还远远不够，有待于进一步改进和
  完善，并期待着新的更有效的理论模型和方法的出现。

当然我们不能忘记，自然语言处理毕竟是认知科学、语言学和计算
机科学等多学科交叉的复杂问题，当我们从外层（或表层）研究语言理
解的理论方法和数学模型的同时，不应该忽略从内层揭示人类理解语言
机制的秘密，从人类认知机理和智能的本质上为自然语言处理寻求依
据。

# 第三章 形式语言与自动机

形式语言与自动机在自然语言处理中具有重要的用途。形式语言理
论是自然语言描述和分析的基础，自动机理论在自然语言的词法分析、
拼写检查和短语识别等很多方面都有着广泛的用途。

## 形式语言

### 什么是语言

乔姆斯基（Noam Chomsky）曾经把**语言**定义为：按照一定规律构成
的句子和符号串的有限或无限的集合。根据这个定义，无论哪一种语言
都是句子和符号串的集合，当然自然语言也不例外，汉语、英语等所有
自然语言，都是一个无限集合。

**语言描述**的三种途径：

* 穷举法：把语言中的所有句子都枚举出来。显然，这种方法
  只适合句子数目有限的语言。
* **文法**（产生式系统）描述：语言中的每个句子用严格定义的
  规则来构造，利用规则生成语言中合法的句子。
* **自动机法**：通过对输入的句子进行合法性检验，区别哪些是
  语言中的句子，哪些不是语言中的句子。

用文法来定义语言的优点是：由文法给予语言
中的句子以结构，各成分之间的结构关系清楚、明了。但是，如果要直
接用这些规则来确定一个字符串是否属于这套规则所定义的语言似乎并
不十分明确。而由自动机来识别一个字符串是否属于该语言则相对简
单，但自动机很难描述语言的结构。所以自然语言处理中的识别和分析
算法，大多兼取两者之长。

可以将文法看成是对语言集合的枚举过程；而自动机则是测试元素是否在集合中。

### 形式语言的定义

形式语言（formal language）是用来精确地描述语言（包括人工语言和自然语言）及其
结构的手段。形式语言学也称代数语言学。

![](formal-language.png)

如果每步推导中只改写最左边的那个非终结符，这种推导称为“最左推导”。反之，如果每次都只改写最右边的非
终结符，则为最右推导。最右推导又称规范推导。

### Chomsky 层级

在乔姆斯基的语法理论中，文法被划分为4种类型：3型文法、2型
文法、1型文法和0型文法，分别称为正则文法、上下文无关文法、上下
文相关文法和无约束文法。

![](regular-grammer.png)



在这种书写格式中，由于规则右部的非终结符号 B（如果有的话）出现在最左边，所以，这种形式的正则文法又叫左线性正则文法。类似的，也有右线性正则文法。总之，非终结符号只能出现在一侧。

![](conext-free-grammer.png)

从定义中我们可以看出，2型文法比3型文法少了一层限制，其规则
右端的格式没有约束。也就是说，规则左部的非终结符可以被改写成任
何形式。

![](context-sensitive-grammer.png)



![](non-constraint-grammer.png)

根据上述定义我们不难看出，从0型文法到3型文法，对规则的约束
越来越多，每一个正则文法都是上下文无关文法，每一个上下无关文法
都是上下文有关文法，而每一个上下文有关文法都可以认为是0型文
法。因此，从0型文法到3型文法所识别的语言集合越来越小。

### 上下文无关文法和语法树

上下文无关文法产生句子的过程可以由语法书（syntactic tree）或者叫解析树（parsing tree）来表示。

![](cfg-parsing-tree.png)

正如上图所见，如果文法G对于同一个句子存在两棵或
两棵以上不同的分析树，那么，该句子是二义性的，文法G为二义性文
法。这就是句法分析中的消除歧义问题。

## 自动机

自动机是一种理想化的“机器”，它只是抽象分析问题的理论工具，
并不具有实际的物质形态。它是科学定义的**演算机器**，用来表达某种不
需要人力干涉的机械性演算过程。根据不同的构成和功能，自动机分成
以下4种类型：有限自动机（finite automata, FA）、下推自动机（pushdown
automata, PDA）、线性界限自动机（linear-bounded automata）和图
灵机（Turing machine）。

### 有限自动机

有限自动机又分为确定性有限自动机（definite finite state automata, DFSA）和不
确定性有限自动机（non-definite finite state automata, NFSA）两种。

#### DFSA

![](DFSA-definition.png)

![](DFSA-graph.png)

#### 用 DFSA 描述语言

![](DFSA-language.png)

所有被自动机接受的句子而所组成的语言就是被自动机 M 定义的语言。

#### NDFSA

![](NDFSA-definition.png)

#### 用 NDFSA 描述语言

同样可以用类似 DFSA 的原理考查一个句子是否可以被 NDFSA 接受，所有被接收的句子集合就是 NDFSA 所定义的语言。

由于给定一个 NDFSA 必然存在一个等价的 DFSA 跟它对应。因此其实二者描述语言的能力也是等价的。

#### 有限自动机描述正则语言

对于任意一个正则文法所产生的语言，总可以构造一个确定的有限自动机识别它。

### 下推自动机

下推自动机（PDA）可以看成是一个带有附加下推存储器的有限自动机，下推存储器是一个堆栈（stack）。

#### 用下推自动机描述语言

![](PFSA-language.png)

对于下推自动机，判断一种语言（或者一个句子）是否被PDA接受的标准有两种：句子结束时自动机是否处于终止状态；句子结束时下推储存器是否为空。

#### 下推自动机描述上下文无关语言

对于任意一个上下文无关文法所产生的语言，总可以构造一个确定的下推自动机识别它。

### 线性界限自动机

线性界限自动机是一个确定的单带图灵机，其读／写头不能超越原
输入带上字符串的初始和终止位置，即线性界限自动机的存储空间被输
入符号串的长度所限制。

如果L是一个上下文相关语言，则L由一个不确定的线性
界限自动机所接受。反之，如果L被一个线性界限自动机所接受，则L是
一个上下文相关语言。

### 图灵机

图灵机与有限自动机的区别在于图灵机可以通过其读写头改变输入
带上的字符，而有限自动机不能做到这一点。

图灵机相应的可以描述 0 型文法（即无约束文法）语言。

### 总结

归纳起来，各类自动机之间的主要区别是它们能够使用的**信息存储
空间**的差异：有限状态自动机只能用状态来存储信息；下推自动机除了
使用状态以外，还可以用下推存储器（堆栈）；线性界限自动机可以利
用状态和输入／输出带本身，因为输入／输出带没有“先进后出”的限
制，因此，其功能大于堆栈；而图灵机的存储空间没有任何限制。
从识别语言的能力上来看，有限自动机等价于正则文法；下推自动
机等价于上下文无关文法；线性界限自动机等价于上下文有关文法，而
图灵机等价于无约束文法。

## 自动机在自然语言处理中的应用

### 单词拼写

K.Oflazer曾将有限自动机用于英语单词的拼写检查［Oflazer,1996］。

一个基于有限状态机的识别器可以看作是一个弧上有字母标记a∈A
的有向图，字母表A上的字母构成的所有合法单词都是有限状态机中的
一条路径。那么，字符串识别的过程就是对有向图从初始状态到终止状
态遍历的过程，一条路径从初始状态到终止状态经过的所有弧上的字母
连接起来构成一个字符串。如果给定一个输入串，对其进行拼写检查的
过程实际上就是在给定阈值t（t＞0）的范围内，寻找所有那些与输入串
的编辑距离（minimum edit distance）小于t的路径，这些路径从初始状态到终止状态经过的所有
弧上的字母连接起来就是要找的与输入串最相似的单词。

为了提高搜索速度，可以把搜索空间限定在一个较小的范围内，尽
早把那些编辑距离超过给定阈值t的路径剪枝。为了判断哪些路径应该
被剪枝，Oflazer提出了剪除编辑距离或剪除距离（cut-off edit distance）
的概念。

### 单词形态分析

在实际应用中，除了有限状态机以外，我们还常常使用有限状态转
换机（finite state transducer, FST）的概念。简单地讲，有限状态转换机
与有限自动机（或有限状态机）的区别在于：FST在完成状态转移的同
时产生一个输出，而FA（或FSM）只实现状态的转移，不产生任何输
出。

用有限状态转换机进行英语单词的形态分析是常用的方法。例如，形容词
heavy在英文句子中可能以三种不同的形式出现：原型、比较级和最高
级。对于变形后的heavy，为了正确分析出其原型，可以通过构造状态
转换机的方法实现

![](FST-example.png)

这个状态图实际上表示的是除了识别heavy单词原型
以外，还可产生如下两条关于单词heavy的形态分析规则：
heavier→heavy＋er
heaviest→heavy＋est

### 词性消歧

一个词往往具有多种词性，如何根据上下文环境对词性消除歧义呢？

词性标注的方法很多，有限状态转换机方法是其中的一种。Roche
and Schabes（1995）在Brill（1992）建立的词性消歧规则的基础上通过
构造状态转换机，实现了一种词性消歧方法。

考虑到在词性标注的第一步需要对处理句子中的每个单词查
找词典，以获取其可能的词性。为了快速实现词典查找这一过程，
Roche and Schabes（1995）对词典的存储也采用了确定的有限状态自动
机的思想：

![](FSA-lexicon.png)

# 第四章 语料库与语言知识库

任何一个信息处理系统都离不开数据和知识库的支持，自然语言处
理系统也不例外。语料库和语言知识库作为基本的资源，尽管在不同方
法的自然语言处理系统中所起的作用不同，但是，它们在不同层面共同
构成了各种自然语言处理方法赖以实现的基础，有时甚至是建立或改进
一个自然语言处理系统的“瓶颈”。

## 语料库语言学

语料库（corpus base）就是存放语言材
料的数据库。那么，顾名思义，语料库语言学（corpus linguistics）就是
基于语料库进行语言学研究的一门学问。具体一点讲，语料库语言学是
研究自然语言机读文本（或称“电子文本”）的采集、存储、标注、检
索、统计等方法的一门学问，其目的是通过对客观存在的大规模真实文
本中的语言事实进行定量分析，为语言学研究或自然语言处理系统开发
提供支持。（**文本数据+统计方法+语言知识**）
有专家认为，语料库语言学这一术语有两层含义，一是利用语料库
对语言的某个方面进行研究，也就是说“语料库语言学”不是一个新学科
的名称，而仅仅反映了一个新的研究手段。二是依据语料库所反映出来
的语言事实对现行语言学理论进行批判，提出新的观点或理论。只有在
这个意义上“语料库语言学”才是一个新学科的名称

## 发展历程

早期的语料库语言学指的是20世纪50年代中期以前，即乔姆斯基提
出的转换生成语法理论之前所有基于语言材料的语言研究。

1957年乔姆斯基的《句法理论》及其以后一系列著作的发表，从根
本上改变了语料库语言学的发展状况。**乔姆斯基及其转换生成语法学派**
否定早期的语料库研究方法的主要依据有如下两点：

* 语料研究的方向有误。乔姆斯基认为，语言研究的主要目标
  是建立一种能够反映说话人心理现实的语言认知模式，即语言能力模
  式。因为只有语言能力才能对说话人的语言知识做出合理的解释和描
  述，而语言运用只是语言能力的外在证据。它往往会因超语言因素而发
  生变化，因此，它不能确切地反映语言能力。语料从本质上只是外在化
  的话语的汇集，基于语料建立的经验模式充其量只是对语言能力做出的部分解释，因而，语料并非语言学家从事语言研究的得力工具。
* 语料的不充分性。乔姆斯基在《句法理论》一书中首次发现
  英语短语结构规则具有递归性。这种递归性表明，自然语言的句子是无
  限的，而作为语料基本单位的句子具有无限性，这种无限性决定了语料
  是难以穷尽的。换句话说，语料永远是不完整、不充分的。

转换生成语法学派的上述批评从根本上改变了20世纪50年代结构主
义语言学的研究方向，在随后的近20年里，整个语言学界几乎唯直觉是
从，基于语料的研究方法由此进入沉寂时期。

在沉寂了近20年之后，语料库语言学自20世纪80年代开始复苏，并
得到迅猛发展，从此进入一个空前繁荣阶段。这主要表现在如下两个方
面：

* 第二代语料库相继建成。
* 基于语料的研究项目大量增加。

语料库语言学在20世纪80年代再度崛起的主要原因可以粗略归结为
如下两条：（1）基于规则的句法—语义分析方法赖以利用的语言知识
无论是词典信息还是语法规则，主要通过语言学家的内省来获取的，而
实际上这种知识不可能覆盖真实文本中出现的所有语言事实；（2）计
算机和计算技术的迅猛发展，使语料库的规模急速增长，从早期的百万
词次猛增到数亿词次。

语料库语言学的复兴，除了与计算机技术的迅速发展和普及有直接
关系以外，还有一方面的原因就是，转换生成语言学派对语料库语言学
的批判和否定在经过20多年的实践检验之后，证明是错误的或者是片面
的。因此，20世纪80年代以来语料库语言学的复兴，在很大程度上反映
了语言学界一种较为普遍的心态，就是建立语言研究中人工数据和自然
数据的平衡，实现语料统计方法和唯理分析方法的优势互补。

## 语料库的类型

根据不同的划分标准，语料库可以分为多种类型。这里主要介绍以下几种划分方法。

### 平衡语料库与平行语料库
**平衡语料库**着重考虑的是语料的代表性与平衡性。

黄昌宁等（2002a）认为，语料库的代表性和平衡性是一个迄今都
没有公认答案的复杂问题。G.N.Leech（1992）曾指出，一个语料库具
有代表性是指在该语料库上获得的分析结果可以概括成为这种语言整体
或其指定部分的特性。早期的Brown语料库和LOB语料库的结构是经过
精心设计的，因此，它们被分别视为美国英语和英国英语在那一特定时
期的代表。

由于语言是动态发展的，每一时期总会有一些词汇被“淘汰”，也总
会有一些新的词语产生，即使同一词语在不同的历史时期使用的频度也
不一样。因此，如何把握语料的平衡性的确是一个复杂的问题。

所谓的**平行语料**一般有两种含义，一种是指在同一种语言的语料上
的平行，例如，“国际英语语料库”，共有20个平行的子语料库，分别来
自以英语为母语或官方语言以及主要语言的国家，如英国、美国、加拿
大、澳大利亚、新西兰等。其平行性表现为语料选取的时间、对象、比
例、文本数、文本长度等几乎是一致的。建库的目的是对不同国家的英
语进行对比研究。对平行语料库的另一种理解是指两种或多种语言之间的平行采样和
加工。例如，机器翻译中的双语对齐语料库（句子对齐或段落对齐）。

### 通用语料库与专用语料库
所谓的通用语料库实际上与平衡语料库是从不同角度看问题的结
果，或者说是与专用领域对举的结果。为了某种专门的目的，只采集某
一特定领域、特定地区、特定时间、特定类型的语料构成的语料库就是
专用语料库。例如，新闻语料库、科技语料库、中小学语料库、北京口
语语料库等。

### 共时语料库与历时语料库
所谓共时语料库是为了对语言进行共时研究而建立的语料库。

无论所采集语料的时
间段有多长，只要研究的是一个平面上的元素或元素的关系，就是共时
研究，所建立的语料库就是共时语料库。

所谓的历时语料库是为了对语言进行历时研究而建立的语料库。根据历时
语料库得到的统计结果就不像共时语料库的统计结果是一个频次点，而
是依据时间轴的等距离抽样得到的若干频次变化形成的演变曲线。

### 生语料与标注语料库
所谓生语料是指没有经过任何加工处理的原始语料数据（corpora
with raw data）。组织者只是简单地把语料收集起来，不加任何标注信
息。

标注语料库是指经过加工处理、标注了特定信息的语料库。根据加
工程度不同，标注语料库又可以细分为分词语料库（主要指汉语）、分
词与词性标注语料库、树库（tree bank）（以句法结构信息为主要标注内容）、命题库（proposition
bank）（以谓词-论元结构信息为主要标注内容）、篇章树库（discourse tree bank）（以篇章结构信息为主要内容）等。

## 汉语语料库建设问题

如下两个问题在汉语语料库建设中表现尤为突出。

### 语料库建设的规范问题
语料库加工的规范问题是语料库建设中的关键问题之一，如果没有
公认的、统一的语料库加工规范，语料库的建设和利用势必会受到严重
制约。

尽管目前我国政府主管部门已经意识到制定中文信息处理所需要的
有关语言文字规范和标准的重要性和紧迫性，并及时提出了《信息处理
用现代汉语词类标记集规范》的立项，但是，到目前为止，这种“规
范”并没有被普遍接受和使用。而且，目前提出的一些“规范”往往只重
视了文本内的语言标记，没有及时制定语料库的规范。对于文本的属性
这一更高层次的规范，至今没有立项。没有规范语料库的属性，没有规
范语料库中文本的属性，语料库的资源就很难重复使用，很难进行语料
库与语料库之间的整合，很难由一些母语料库去整合生成一些新的子语
料库［张普，2003］。实际上，这也是语料资源长期无法共享，大量语
料库处于小规模、低水平、重复建设状态的主要原因之一。

### 产权保护和国家语料库建设问题
张普认为，汉语语料库和世界各国的语料库一样都面临知识产权的
问题，这个问题不从根本上解决，将严重影响我国的语料库建设及其应
用。

在信息社会和数字化生存时代，我们要把语言资源的收集、
保护、开发提高到一种对待国家资源的高度来认识。国家要像对待人力
资源、地矿资源、国土资源、森林资源、水源资源一样对待语言资源，
语言资源是国家最重要的信息资源。语料库的建设、保护、开发要站在
国家面向未来的一种战略决策高度，要作为一种对待国家资源的行为，
才能得到法律的保护，纳入法制的轨道［张普，2003］。

## 典型语料库

详见书籍

## 语言知识库

语言知识库在自然处理和语言学研究中具有重要的用途，无论是词
汇知识库、句法规则库，还是语法信息库、语义概念库等各类语言知识
资源，都是自然语言处理系统赖以建立的重要基础，甚至是不可或缺的
基础。

需要说明的是，“语言知识库”比“语料库”包含更广泛的内容。概括
起来讲，语言知识库可分为两种不同的类型：一类是词典、规则库、语
义概念库等，其中的语言知识表示是显性的，可采用形式化结构描述；
另一类语言知识存在于语料库之中，每个语言单位的出现，其范畴、意
义、用法都是确定的。语料库的主体是文本，即语句的集合，每个语句
都是线性的非结构化的文字序列，其中包含的知识都是隐性的。语料加
工的目的就是要把隐性的知识显性化，以便于机器学习和引用。

### WordNet

WordNet是由美国普林斯顿大学（Princeton University）认知科学实
验室（Cognitive Science Laboratory〔22〕）George A.Miller领导的研究组
开发的英语机读词汇知识库。

WordNet的建立有三个基本前提：①“可分离性假设（separability
hypothesis）”，即语言的词汇成分可以被离析出来并专门针对它加以研
究。 ②“模式假设（patterning hypothesis）”：一个人不可能掌握他运用
一种语言所需的所有词汇，除非他能够利用词义中存在的系统的模式和
词义之间的关系。 ③“广泛性假设（comprehensiveness hypothesis）”：计
算语言学如果希望能像人那样处理自然语言，就需要像人那样储存尽可
能多的词汇知识［Miller et al.,1993］。

WordNet描述的对象包含英语复合词（compound）、短语动词
（phrasal verb）、搭配词（collocation）、成语（idiomatic phrase）和单
词（word），其中，单词（word）是最基本的单位。

它既不同于传统的词典（dictionary），也不同于同义词词典（thesaurus），而
是混合了这两种类型的词典：

* WordNet与同义词词林相似，它也是
  以同义词集合（synset）作为基本的建构单位（building block）组织的，
  如果用户自己有一个已知的概念，就可以在同义词集合中找到一个适合
  的词去表达这个概念。与传统的词典相似的是WordNet给出了同义词集
  合的定义和例句，在同义词集合中包含对这些同义词的定义。对一个同
  义词集合中的不同词，分别用适当的例句加以区分。
* WordNet不只是用同义词
  集合的方式罗列概念，而且同义词集合之间是以一定数量的关系类型相
  互关联的。这些关系包括同义关系（synonymy）、反义关系
  （antonymy）、上下位关系（hypernymy/hyponymy）、整体与部分关系
  （meronymy）和继承关系（entailment）等，其基础语义关系是同义关
  系。
* 但WordNet中不包括发音、派生形态、词源信
  息、用法说明、图示举例等，而是尽量使词义之间的关系明晰并易于使
  用。
* 在WordNet中，大多数同义词集合（synset）有说明性的注释
  （explanatory gloss）

综上所述，WordNet是一个按语义关系网络组织的巨大词库，多种
**词汇关系**和**语义关系**被用来表示词汇知识的组织方式。词形式（word
form）和词义（word meaning）是WordNet源文件中可见的两个基本构
件，词形式以规范的词形表示，词义以同义词集合（synset）表示。词
汇关系是两个词形式之间的关系，而语义关系是两个词义之间的关系。

### FrameNet

在FrameNet中，框架是组织词汇语义知识的基本手段。每个词汇单
元（lexical unit, LU）是由词和对应的一个词义构成的词汇－词义对。

对自然语言处
理的研究者来说，FrameNet是一个标注了170000多个句子的训练集，可
用于语义角色标注研究。从事FrameNet研究的Berkeley课题组还定义了
1000多个语义框架，通过一个框架关系系统将它们连接在一起，为事件
和意图行为推理提供了基础。

### 北京大学综合型语言知识库

北京大学计算语言学研究所（ICL/PKU）俞士汶教授领导建立的综
合型语言知识库（简称CLKB）涵盖了词、词组、句子、篇章各单位和
词法、句法、语义各层面，从汉语向多语言辐射，从通用领域深入到专
业领域。CLKB是目前国际上规模最大且获得广泛认可的汉语语言知识
资源。

GKB以复杂特征集和合一运算理论为依据，采用“属性—属性值”的
形式详细描述词语的句法知识。

现代汉语多级标注语料库（word-sense tagging corpus, STC）是
ICL/PKU在对《人民日报》语料进行词语切分和词性标注，建立的大规
模现代汉语基本标注语料库（规模达6000万字）的基础上，以《语法信
息词典》和《语义词典》为参考，加注不同粒度的词义信息之后形成
的。基本标注语料库中的人名、地名及团体机构名等命名实体，都用相
应标记予以了标识。

### HowNet

知网（HowNet）是机器翻译专家董振东和董强经过十多年的艰苦
努力创建的语言知识库，是一个以汉语和英语的词语所代表的概念为描
述对象，以揭示概念与概念之间以及概念所具有的属性之间的关系为基
本内容的常识知识库。

（1）自然语言处理系统最终需要强大的知识库支持。
（2）关于什么是知识，尤其关于什么是计算机可处理的知识，他
提出：知识是一个系统，是一个包含着各种概念与概念之间的关系，以
及概念的属性与属性之间的关系的系统。
（3）关于如何建立知识库，他提出应首先建立一种可以被称为知
识系统的常识性知识库，它以通用的概念为描述对象，建立并描述这些
概念之间的关系。
（4）关于由谁来建立知识库，他指出知识掌握在千百万人的手
中，知识又是那么博大精深，靠三五个人甚至三五十人是不可能建立真
正意义上的全面的知识库的。他指出：首先应该由知识工程师来设计知
识库的框架，并建立常识性知识库原型。在此基础上再向专业性知识库
延伸和发展。专业性知识库或称百科性知识库，主要靠专业人员来完
成。

基于上述观点，董振东提出了知网系统的哲学思想：世界上一切事
物（物质的和精神的）都在特定的时间和空间内不停地运动和变化。它
们通常是从一种状态变化到另一种状态，并通常由其属性值的改变来体
现。比如，人的生、老、病、死是一生的主要状态，这个人的年龄（属
性）一年比一年大{属性值}，随着年龄的增长头发的颜色（属性）变为
灰白{属性值}。

知网是一个知识系统，而不是一部语义词典。知网用概念与概念之
间的关系以及概念的属性与属性之间的关系形成一个网状的知识系统，
这是它与其他树状词汇数据库的本质不同。

### 概念层次网络

概念层次网络（Hierarchical Network of Concepts, HNC）是中国科学
院声学研究所黄曾阳建立的面向整个自然语言理解的理论框架。，HNC理论创立了基于语义的自然语言表述和处理模式。

传统的语言表示和处理模式以语法为基础。语法有狭义与广义之分，狭
义语法是指以形态变化和虚词搭配为依托的语言法则，这些法则里本来
包含语义信息，但语法学从自身研究的便利出发曾长期有意脱离语义而
自成体系。这个状况直到乔姆斯基的转换生成语法和菲尔墨的格语法出
现以后才发生了变化，随后的功能语法继承了乔姆斯基和菲尔墨的传
统，这些语法应称为广义语法，它包含了语义甚至语用。但是，广义语
法学虽然融入了语义知识，并未对语义表述给出完善的理论框架。HNC
理论从根本上改变了这一状况，“根本”的具体表现就是建立了表述自然
语言概念和语句的两套数学表示式［苗传江，1998］。

## 语言知识库与本体论

详见书籍

# 第五章 语言模型

语言模型（language model, LM）在自然语言处理中占有重要的地
位，尤其在基于统计模型的语音识别、机器翻译、汉语自动分词和句法
分析等相关研究中得到了广泛应用。目前主要采用的是n元语法模型
（n-gram model），这种模型构建简单、直接，但同时也因为数据缺乏
而必须采取平滑（smoothing）算法。

## N元语法模型

详见书籍

## 各种平滑技术

详见书籍

## 自适应语言模型

在自然语言处理系统中，语言模型的性能好坏直接影响整个系统的
性能。尽管语言模型的理论基础已比较完善，但在实际应用中常常会遇
到一些难以处理的问题。其中，模型对跨领域的脆弱性（brittleness
across domains）和独立性假设的无效性（false independence
assumption）是两个最明显的问题。也就是说，一方面在训练语言模型
时所采用的语料往往来自多种不同的领域，这些综合性语料难以反映不
同领域之间在语言使用规律上的差异，而语言模型恰恰对于训练文本的
类型、主题和风格等都十分敏感；另一方面，n元语言模型的独立性假
设前提是一个文本中的当前词出现的概率只与它前面相邻的n-1个词相
关，但这种假设在很多情况下是明显不成立的。另外，香农实验
（Shannon-style experiments）表明，相对而言，人更容易运用特定领域
的语言知识、常识和领域知识进行推理以提高语言模型的性能（预测文
本的下一个成分）［Rosenfeld,2000］。因此，为了提高语言模型对语
料的领域、主题、类型等因素的适应性，［Kupiec,1989］和［Kuhn and
De Mori, 1990］等提出了自适应语言模型（adaptive language model）的
概念。

### 基于缓存的语言模型

基于缓存的语言模型自适应方法针对的问题是，在文本中刚刚出现
过的一些词在后边的句子中再次出现的可能性往往较大，比标准的n元
语法模型预测的概率要大。针对这种现象，cache-based自适应方法的基
本思路是，语言模型通过n元语法和缓存概率的线性插值求得：

![](cache-based-language-model.png)

其中缓存概率求解的直观是：人们希望越是临近的词，对缓存概率的贡献越大。

![](cache-based-language-model-cache-prob.png)

### 基于混合方法的自适应语言模型

基于混合方法的自适应语言模型针对的问题是，由于大规模训练语
料本身是异源的（heterogenous），来自不同领域的语料无论在主题
（topic）方面，还是在风格（style）方面，或者同时在这两方面都有一
定的差异，而测试语料一般是同源的（homogeneous），因此，为了获
得最佳性能，语言模型必须适应各种不同类型的语料对其性能的影响。
基于混合方法的自适应语言模型的基本思想是，将语言模型划分成
n个子模型M1，M2，…，Mn，整个语言模型的概率通过下面的线性插值
公式计算得到：

![](mixture-based-language-model.png)

### 基于最大熵的语言模型

上面介绍的两种语言模型自适应方法采用的思路都是分别建立各个
子模型，然后，将子模型的输出组合起来。基于最大熵的语言模型却采
用不同的实现思路，即通过结合不同信息源的信息构建一个语言模型。
每个信息源提供一组关于模型参数的约束条件，在所有满足约束的模型
中，选择熵最大的模型。

由于最大熵模型能够较好地将来自不同信息源的模型结合起来，获
得性能较好的语言模型，因此，有些学者研究将基于主题的语言模型
（topic-based LM）（主题条件约束）与n元语法模型相结合，用于对话
语音识别、信息检索（information retrieval, IR）和隐含语义分析

# 第六章 概率图模型

![](PGM-examples.png)

动态贝叶斯网络（dynamic Bayesian networks, DBN）用于处理随时
间变化的动态系统中的推断和预测问题。其中，隐马尔可夫模型
（hidden Markov model, HMM）在语音识别、汉语自动分词与词性标注
和统计机器翻译等若干语音语言处理任务中得到了广泛应用；卡尔曼滤
波器则在信号处理领域有广泛的用途。马尔可夫网络（Markov
network）又称马尔可夫随机场（Markov random field, MRF）。马尔可夫
网络下的条件随机场（conditional random field, CRF）广泛应用于自然语
言处理中的序列标注、特征选择、机器翻译等任务，波尔兹曼机
（Boltzmann machine）近年来被用于依存句法分析［Garg and Henderson,
2011］和语义角色标注［庄涛，2012］等。

![](PGM-history.png)



由于自然语言处理中需要解决的问题大多数属于“线”的序列结构，因此我们分别
以HMM（生成式）和线性链式CRF（判别式）为例来介绍自然语言处
理中的概率图模型。其中，HMM以朴素贝叶斯（naΪve Bayes）为基础，
CRF以逻辑回归为基础。

## 贝叶斯网络 - BN

贝叶斯网络又称为信度网络或信念网络（belief networks），是一种
基于概率推理的数学模型，其理论基础是贝叶斯公式。贝叶斯网络的概
念最初是由Judea Pearl于1985年提出来的〔1〕，其目的是通过概率推理处
理不确定性和不完整性问题。

形式上，一个贝叶斯网络就是一个有向无环图（directed acyclic
graph, DAG），结点表示随机变量，可以是可观测量、隐含变量、未知
参量或假设等；结点之间的有向边表示条件依存关系，箭头指向的结点
依存于箭头发出的结点（父结点）。

![](Bayes-network-example.png)

### 马尔可夫模型 - MM

马尔可夫模型是一种用于对随机过程建模的贝叶斯网络模型。

我们知道，随机过程又称随机函数，是随时间而随机变化的过程。
马尔可夫模型（Markov model）描述了一类重要的随机过程。我们常常
需要考察一个随机变量序列，这些随机变量并不是相互独立的，每个随
机变量的值依赖于这个序列前面的状态。如果一个系统有N个有限状态
S＝{s1，s2，…，sN}，那么随着时间的推移，该系统将从某一状态转移
到另一状态。Q＝（q1，q2，…，qT）为一个随机变量序列，随机变量
的取值为状态集S中的某个状态，假定在时间t的状态记为qt。对该系统
的描述通常需要给出当前时刻t的状态和其前面所有状态的关系：

![](1-order-markov-chain.png)

可见马尔可夫模型对序列数据做出了很强的条件独立假设。马尔科夫模型由状态集合、初始状态概率以及状态转移概率来定义。

马尔可夫模型又可视为**随机的有限状态机**。对于每个状态来说，发出弧上的概率和为1。从图可以看出，马尔可夫模型可以看作是一个转移弧上有概率的非确定的有限状态自动机。

![](markov-SFSA.png)

此外，我们可以看出n元语法模型就是n-1阶马尔可夫模型。

### 隐马尔可夫模型 - HMM

在马尔可夫模型中，每个状态代表了一个可观察的事件，所以，马
尔可夫模型有时又称作可视马尔可夫模型（visible Markov model，
VMM），这在某种程度上限制了模型的适应性。在隐马尔可夫模型
（HMM）中，我们不知道模型所经过的状态序列，只知道状态的概率
函数，也就是说，观察到的事件是状态的随机函数，因此，该模型是一
个双重的随机过程。其中，模型的状态转换过程是不可观察的，即隐蔽
的，可观察事件的随机过程是隐蔽的状态转换过程的随机函数。

![](HMM-example.png)



一般地，一个HMM记为一个五元组μ＝（S，K，A，B，π），其
中，S为状态的集合，K为输出符号的集合，π，A和B分别是初始状态的
概率分布、状态转移概率和符号发射概率。为了简单，有时也将其记为
三元组μ＝（A，B，π）。

### HMM 三个要求解的问题

![](HMM-3-problems.png)

#### 观察序列的概率求解

前向算法；后向算法；

#### 最可能状态序列求解

Viterbi 算法

#### HMM 模型的参数估计

EM 算法

### 层次化的隐马尔可夫模型 - HHMM

当序列长度较大时，隐马尔可夫模型的复杂度将会急剧增大，因此，Shai
Fine等人提出了层次化隐马尔可夫模型（hierarchical hidden Markov
models, HHMM）

## 马尔可夫网络 - MRF

马尔可夫网络（又称为马尔可夫随机场 Markov random field）与贝叶斯网络有类似之处，也可用于表示变量之间的
依赖关系。但是，它又与贝叶斯网络有所不同。一方面，它可以表示贝
叶斯网络无法表示的一些依赖关系，如循环依赖；另一方面，它不能表
示贝叶斯网络能够表示的某些关系，如推导关系。

马尔可夫网络是一组有马尔可夫性质的随机变量的联合概率分布模
型，它由一个无向图G和定义于G上的势函数组成。

![](Markov-network-example.png)

## 最大熵模型 - MEM

最大熵模型的基本原理是：在只掌握关于未知分布的部分信息的情
况下，符合已知知识的概率分布可能有多个，但使熵值最大的概率分布
最真实地反映了事件的分布情况，因为熵定义了随机变量的不确定性，
当熵最大时，随机变量最不确定，最难准确地预测其行为。也就是说，
在已知部分信息的前提下，关于未知分布最合理的推断应该是符合已知
信息最不确定或最大随机的推断。

## 最大熵马尔可夫模型 - MEMM

最大熵马尔可夫模型（maximum-entropy Markov model, MEMM）又
称条件马尔可夫模型（conditional Markov model, CMM），由Andrew
McCallum, Dayne Freitag和Fernando Pereira三人于2000年提出［McCallum
et al., 2000］。它结合了隐马尔可夫模型和最大熵模型的共同特点，被
广泛应用于处理序列标注问题。

文献［McCallum et al., 2000］认为，在HMM模型中存在两个问
题：①在很多序列标注任务中，尤其当不能枚举观察输出时，需要用大
量的特征来刻画观察序列。如在文本中识别一个未见的公司名字时，除
了传统的单词识别方法以外，还需要用到很多特征信息，如大写字母、
结尾词、词性、格式、在文本中的位置等。也就是说，我们需要用特征
对观察输出进行参数化。②在很多自然语言处理任务中，需要解决的问
题是在已知观察序列的情况下求解状态序列，HMM采用生成式的联合
概率模型（状态序列与观察序列的联合概率P（ST，OT））来求解这种
条件概率问题P（ST|OT）（参见6.4节），这种方法不适合处理用很多特
征描述观察序列的情况。为此，MEMM直接采用条件概率模型
P（ST|OT），从而使观察输出可以用特征表示，借助最大熵框架进行特
征选取。

![](HMM-MEMM-example.png)

在HMM中，当前时刻的观察输出只取决于当前状态，而在MEMM中，当前时刻的观察输出还可能
取决于前一时刻的状态。

HMM 解码时求解：

![](HMM-decode-math.png)

MEMM 解码时求解：

![](MEMM-decode-math.png)



MEMM是有向图和无向图的混合模型，其主体还是有向图框架。与
HMM相比，MEMM的最大优点在于它允许使用任意特征刻画观察序
列，这一特性有利于针对特定任务充分利用领域知识设计特征。MEMM
与HMM和条件随机场（conditional random fields, CRFs）模型（见6.9
节）相比，MEMM的参数训练过程非常高效，在HMM和CRF模型的训
练中，需要利用前向后向算法作为内部循环，而在MEMM中估计状态转
移概率时可以逐个独立进行。MEMM的缺点在于存在标记偏置问题
（label bias problem），其中一个原因是熵低的状态转移分布会忽略它
们的观察输出，而另一个原因是MEMM像HMM一样，其参数训练过程
是自左向右依据前面已经标注的标记进行的，一旦在实际测试时前面的
标记不能确定时，MEMM往往难以处理。

## 条件随机场 - CRF

条件随机场（conditional random fields, CRFs）由J. Lafferty等人
（2001）提出，近几年来在自然语言处理和图像处理等领域中得到了广
泛的应用。
CRF是用来标注和划分序列结构数据的概率化结构模型。言下之
意，就是对于给定的输出标识序列Y和观测序列X，条件随机场通过定
义条件概率P（Y|X），而不是联合概率分布P（X，Y）来描述模型。
CRF也可以看作一个无向图模型或者马尔可夫随机场（Markov random
field）［Wallach, 2004］。

![](CRF-chain-structure.png)

相对于HMM，CRF的主要优点在于它的条件随机性，只需要考虑
当前已经出现的观测状态的特性，没有独立性的严格要求，对于整个序
列内部的信息和外部观测信息均可有效利用，避免了MEMM和其他针对
线性序列模型的条件马尔可夫模型会出现的标识偏置问题。CRF具有
MEMM的一切优点，两者的关键区别在于，MEMM使用每一个状态的
指数模型来计算给定前一个状态下当前状态的条件概率，而CRF用单个
指数模型来计算给定观察序列与整个标记序列的联合概率。因此，不同
状态的不同特征权重可以相互交替代换